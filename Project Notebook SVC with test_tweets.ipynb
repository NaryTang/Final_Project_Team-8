{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"Data_cyb.json\", lines = True, orient = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "for i in df[\"annotation\"]:\n",
    "    rating.append(int(i[\"label\"][0]))\n",
    "    \n",
    "df[\"rating\"] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>content</th>\n",
       "      <th>extras</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      annotation  \\\n",
       "0  {'notes': '', 'label': ['1']}   \n",
       "1  {'notes': '', 'label': ['1']}   \n",
       "2  {'notes': '', 'label': ['1']}   \n",
       "3  {'notes': '', 'label': ['1']}   \n",
       "4  {'notes': '', 'label': ['1']}   \n",
       "\n",
       "                                             content  extras  rating  \n",
       "0                             Get fucking real dude.     NaN       1  \n",
       "1   She is as dirty as they come  and that crook ...     NaN       1  \n",
       "2   why did you fuck it up. I could do it all day...     NaN       1  \n",
       "3   Dude they dont finish enclosing the fucking s...     NaN       1  \n",
       "4   WTF are you talking about Men? No men thats n...     NaN       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Test_Twitter_Comments.csv' does not exist: b'Test_Twitter_Comments.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b086438aa357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test_Twitter_Comments.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Test_Twitter_Comments.csv' does not exist: b'Test_Twitter_Comments.csv'"
     ]
=======
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>That is someone who does it from their heart. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Absolutely applaud your work to secure freedom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>You'll never learn it till you actually live i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nothing on the reinstatement of federal Capito...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Crickets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  rating\n",
       "96   That is someone who does it from their heart. ...       1\n",
       "97   Absolutely applaud your work to secure freedom...       0\n",
       "98   You'll never learn it till you actually live i...       1\n",
       "99   Nothing on the reinstatement of federal Capito...       1\n",
       "100                                           Crickets       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"Test_Twitter_Comments.csv\")\n",
    "tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = df[[\"content\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ca76008aa4fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_df1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "source": [
    "new_df = pd.concat([new_df1,tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "source": [
    "X, X_test, y, y_test = train_test_split(new_df[\"content\"], new_df[\"rating\"], train_size = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(X)\n",
    "reviews_test_clean = preprocess_reviews(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6742942420097003\n",
      "Accuracy for C=0.05: 0.7071259793558016\n",
      "Accuracy for C=0.25: 0.747419475189653\n",
      "Accuracy for C=0.5: 0.7658251461261038\n",
      "Accuracy for C=1: 0.7833602785723168\n",
      "Final Accuracy: 0.8266600348172096\n"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6643452306926999\n",
      "Accuracy for C=0.05: 0.7024001989802263\n",
      "Accuracy for C=0.25: 0.7426936948140779\n",
      "Accuracy for C=0.5: 0.7557517721676409\n",
      "Accuracy for C=1: 0.774033080462629\n",
      "Final Accuracy: 0.8328773936831634\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "baseline_vectorizer = CountVectorizer(binary=True)\n",
    "baseline_vectorizer.fit(reviews_train_clean)\n",
    "X_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
    "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_baseline, y, train_size = 0.5\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "\n",
    "\n",
    "final_model = LogisticRegression(C=1)\n",
    "final_model.fit(X_baseline, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_model.predict(X_test_baseline)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stop Words\n",
    "Removing Stop Words\n",
    "\n",
    "Stop words are the very common words like ‘if’, ‘but’, ‘we’, ‘he’, ‘she’, and ‘they’. We can usually remove these \n",
    "\n",
    "words without changing the semantics of a text "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 14,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 15,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6672469534941556\n",
      "Accuracy for C=0.05: 0.7199701566774435\n",
      "Accuracy for C=0.25: 0.7749316090524745\n",
      "Accuracy for C=0.5: 0.7935836856503358\n",
      "Accuracy for C=1: 0.8067644864461577\n"
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.659537428500373\n",
      "Accuracy for C=0.05: 0.7097736881372793\n",
      "Accuracy for C=0.25: 0.7716985824421786\n",
      "Accuracy for C=0.5: 0.789107187266849\n",
      "Accuracy for C=1: 0.809002735637901\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
    "no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(no_stop_words_train)\n",
    "X = cv.transform(no_stop_words_train)\n",
    "X_test = cv.transform(no_stop_words_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "A common next step in text preprocessing is to normalize the words in your corpus by trying to convert all of the different forms of a given word into one. Two methods that exist for this are Stemming and Lemmatization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6799303655807013\n",
      "Accuracy for C=0.05: 0.7266849042526735\n",
      "Accuracy for C=0.25: 0.7786620243720468\n",
      "Accuracy for C=0.5: 0.7935836856503358\n",
      "Accuracy for C=1: 0.8117383735389206\n",
      "Final Accuracy: 0.8177070380502363\n"
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6672469534941556\n",
      "Accuracy for C=0.05: 0.7152449639393186\n",
      "Accuracy for C=0.25: 0.769211638895797\n",
      "Accuracy for C=0.5: 0.7953245461328028\n",
      "Accuracy for C=1: 0.8107435961203681\n",
      "Final Accuracy: 0.7237005719970157\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(stemmed_reviews_train)\n",
    "X = cv.transform(stemmed_reviews_train)\n",
    "X_test = cv.transform(stemmed_reviews_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_stemmed = LogisticRegression(C=1)\n",
    "final_stemmed.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_stemmed.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6871425018652076\n",
      "Accuracy for C=0.05: 0.7289231534444168\n",
      "Accuracy for C=0.25: 0.7744342203431982\n",
      "Accuracy for C=0.5: 0.7893558816214872\n",
      "Accuracy for C=1: 0.8047749316090524\n",
      "Final Accuracy: 0.8182044267595125\n"
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.666252176075603\n",
      "Accuracy for C=0.05: 0.715991047003233\n",
      "Accuracy for C=0.25: 0.7716985824421786\n",
      "Accuracy for C=0.5: 0.8007958219348421\n",
      "Accuracy for C=1: 0.8159661775677692\n",
      "Final Accuracy: 0.7846306888833623\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "def get_lemmatized_text(corpus):\n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test_clean)\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(lemmatized_reviews_train)\n",
    "X = cv.transform(lemmatized_reviews_train)\n",
    "X_test = cv.transform(lemmatized_reviews_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_lemmatized = LogisticRegression(C=1)\n",
    "final_lemmatized.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_lemmatized.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams\n",
    "\n",
    "Last time we used only single word features in our model, which we call 1-grams or unigrams. We can potentially add more predictive power to our model by adding two or three word sequences (bigrams or trigrams) as well. For example, if a review had the three word sequence “didn’t love movie” we would only consider these words individually with a unigram-only model and probably not capture that this is actually a negative sentiment because the word ‘love’ by itself is going to be highly correlated with a positive review.\n",
    "The scikit-learn library makes this really easy to play around with. Just use the ngram_range argu"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7246953494155682\n",
      "Accuracy for C=0.05: 0.837105197712012\n",
      "Accuracy for C=0.25: 0.8833623476747078\n",
      "Accuracy for C=0.5: 0.8870927629942801\n",
      "Accuracy for C=1: 0.8875901517035564\n",
      "Final Accuracy: 0.9112161153941806\n"
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7351405123103706\n",
      "Accuracy for C=0.05: 0.8353643372295448\n",
      "Accuracy for C=0.25: 0.8696841581696095\n",
      "Accuracy for C=0.5: 0.8716737130067147\n",
      "Accuracy for C=1: 0.8729171847799055\n",
      "Final Accuracy: 0.9146978363591146\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_ngram = LogisticRegression(C=1)\n",
    "final_ngram.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6851529470281025\n",
<<<<<<< HEAD
      "Accuracy for C=0.05: 0.7276796816712261\n",
      "Accuracy for C=0.25: 0.7726933598607312\n",
      "Accuracy for C=0.5: 0.799054961452375\n",
      "Accuracy for C=1: 0.8214374533698086\n",
      "Final Accuracy: 0.7169858244217856\n"
=======
      "Accuracy for C=0.05: 0.7244466550609301\n",
      "Accuracy for C=0.25: 0.7809002735637901\n",
      "Accuracy for C=0.5: 0.7975627953245461\n",
      "Accuracy for C=1: 0.8149714001492167\n",
      "Final Accuracy: 0.7256901268341208\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train_clean)\n",
    "X = wc_vectorizer.transform(reviews_train_clean)\n",
    "X_test = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75, \n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_wc = LogisticRegression(C=0.05)\n",
    "final_wc.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_wc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "Another common way to represent each document in a corpus is to use the tf-idf statistic (term frequency-inverse\n",
    "\n",
    "document frequency) for each word, which is a weighting factor that we can use in place of binary or word count \n",
    "\n",
    "representations."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6177567769211639\n",
      "Accuracy for C=0.05: 0.6545635414076101\n",
      "Accuracy for C=0.25: 0.7217110171599105\n",
      "Accuracy for C=0.5: 0.7532952001989555\n",
      "Accuracy for C=1: 0.7766724695349415\n",
      "Final Accuracy: 0.7470778413330017\n"
=======
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.5998507833872171\n",
      "Accuracy for C=0.05: 0.6351653817458344\n",
      "Accuracy for C=0.25: 0.7187266849042526\n",
      "Accuracy for C=0.5: 0.7433474260134295\n",
      "Accuracy for C=1: 0.7719472767968167\n",
      "Final Accuracy: 0.7562795324546133\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "final_tfidf = LogisticRegression(C=1)\n",
    "final_tfidf.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_tfidf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still has room to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "Recall that linear classifiers tend to work well on very sparse datasets (like the one we have). Another algorithm that can produce great results with a quick training time are Support Vector Machines with a linear kernel.\n",
    "Here’s an example with an n-gram range from 1 to 2:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 24,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Accuracy for C=0.01: 0.8174583436955981\n",
      "Accuracy for C=0.05: 0.8634667993036558\n",
      "Accuracy for C=0.25: 0.8602337726933599\n",
      "Accuracy for C=0.5: 0.8560059686645113\n",
      "Accuracy for C=1: 0.8500373041531957\n"
=======
      "Accuracy for C=0.01: 0.8234270082069137\n",
      "Accuracy for C=0.05: 0.8647102710768465\n",
      "Accuracy for C=0.25: 0.8614772444665506\n",
      "Accuracy for C=0.5: 0.8599850783387217\n",
      "Accuracy for C=1: 0.8560059686645113\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 25,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Final Accuracy: 0.8858492912210892\n"
=======
      "Final Accuracy: 0.8975379258890823\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "final_svm_ngram = LinearSVC(C=0.05)\n",
    "final_svm_ngram.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final_svm_ngram.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 23,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 24,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Accuracy for C=0.04: 0.8117149608257679\n",
      "Accuracy for C=0.05: 0.8120880487501555\n",
      "Accuracy for C=0.06: 0.8115905981843055\n",
      "Accuracy for C=0.07: 0.8143265762964805\n",
      "Accuracy for C=0.08: 0.814699664220868\n",
      "Accuracy for C=0.09: 0.815445840069643\n",
      "Accuracy for C=0.1: 0.8150727521452555\n",
      "Accuracy for C=0.11: 0.8156945653525681\n",
      "Accuracy for C=0.12: 0.8145753015794055\n",
      "Accuracy for C=0.13: 0.8137047630891681\n",
      "Accuracy for C=0.14: 0.8135804004477055\n",
      "Accuracy for C=0.15: 0.813953488372093\n",
      "Final Accuracy: 0.845560805769709\n"
=======
      "Accuracy for C=0.04: 0.8087302574306678\n",
      "Accuracy for C=0.05: 0.8092277079965179\n",
      "Accuracy for C=0.06: 0.8114662355428429\n",
      "Accuracy for C=0.07: 0.8114662355428429\n",
      "Accuracy for C=0.08: 0.8103469717696804\n",
      "Accuracy for C=0.09: 0.8089789827135928\n",
      "Accuracy for C=0.1: 0.8066160925258052\n",
      "Accuracy for C=0.11: 0.8052481034697176\n",
      "Accuracy for C=0.12: 0.8046262902624052\n",
      "Accuracy for C=0.13: 0.8033826638477801\n",
      "Accuracy for C=0.14: 0.8022634000746176\n",
      "Accuracy for C=0.15: 0.8028852132819301\n",
      "Final Accuracy: 0.8522755533449391\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.5\n",
    ")\n",
    "\n",
    "ccc = []\n",
    "c_scores = []\n",
    "\n",
    "for c in [0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    ccc.append(c)\n",
    "    c_scores.append(accuracy_score(y_val, svm.predict(X_val)))   \n",
    "                    \n",
    "final = LinearSVC(tol=.000001,C=0.01)\n",
    "final.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final.predict(X_test)))\n",
    "\n",
    "                    \n",
    "import matplotlib.pyplot as plt    \n",
    "                    \n",
    "plt.plot(ccc, c_scores)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 55,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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\n",
=======
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VfX9x/HXJ5uEJKyAkABhTxEkTJGKtApoxVWGgoggDrS/Vv3V0eVqrbVVWxkCblzgaq2iOMCNQNiyAwgJM8geSUjy/f2RS38xItyQ5J57b97PxyOP3nHOPe9vg3nfe86532POOURERCK8DiAiIsFBhSAiIoAKQUREfFQIIiICqBBERMRHhSAiIoAKQUREfFQIIiICqBBERMQnyusA5VGvXj2Xnp7udQwRkZCxaNGi3c65FH+WDalCSE9PJzMz0+sYIiIhw8w2+7usdhmJiAigQhARER8VgoiIACoEERHxUSGIiAigQhARER8VgoiIACH2PQT5oQ25h/j30m0QqEuhmnHRmQ1pc0ZiYLYnIgGjQghh+YVFXPfcQjZ/dwSzwGzTOXjq841MuKoL57dtEJiNikhAqBBC2LNffsvm747wwnXd6dvar2+mV9iuA3lc9/xCxj6fyX2DOzKyZ9OAbFdEqp6OIYSo3IP5TJiTRf+29QNWBgD1k+KYMa4X57Wpz+//9Q0PzVpNcXGAdleJSJVSIYSov81eS35hEb+9qF3At50QG8XUkV0Z0bMJUz7byK2vLCHvWFHAc4hI5dIuoxD0zdb9zFyUzdg+zWieUtOTDFGRETwwuCNN6sTz51lr2HEgj2nXZFAnIcaTPCJScfqEEGKcc9z3n5XUiY/h1v6tPM1iZozr24KJV53Niq37uXzSl2zafdjTTCJy+lQIIebdFdtZ+O1e7riwDUlx0V7HAeCiTg155foe7D96jMsnfcmizXu8jiQip0GFEELyjhXx0Kw1tGuYxJCMxl7H+Z6uTevw1s3nkFwjmuHT5vPu8u1eRxKRclIhhJCpn21k676j/PHn7YmMCNAXD8ohvV4Cb958Dp1Skxn/8mKmfLoBF6gvzIlIhakQQsT2/UeZ/MkGBnY8g57N63od50fVSYjhxbE9uOjMhjz03hp+/+9vKCwq9jqWiPhBZxmFiIffW0ORc9wzKPCnmZZXXHQkTwzvQlqdGkz5dCNb9x5lwlVnkxCrf24iwUyfEELA4i17+dfSbVx/bjMa14n3Oo5fIiKMuwe248FLO/LpulyGTJnHzgN5XscSkZNQIQS54mLHff9ZRf3EWG4+r6XXccptRM+mPD2qG5t2H+ayiV+ydsdBryOJyI9QIQS5t5ZsZVn2Pu4c0DZkd7n0a1ufmTf0orDYceXkr/gya7fXkUTkBFQIQexwfiEPv7+GsxrX4rIuqV7HqZCOqcm8Nf4cGtWqwahnFvBaZrbXkUSkDBVCEJv8yQZ2HcznDxe3JyIITzMtr9RaNXjtpl70bF6X/319OY9+uE6npYoEERVCkMrec4Spn2/k0s6N6Nq0ttdxKk1SXDTPju7GlV3T+OfH67l95jIKCnVaqkgwCM2d0tXAQ++tJtKMOwe29TpKpYuOjOCRKzvRpE48j364ju3783hyRFeS44NjKg6R6kqfEILQ1xu/Y9aKHdz4kxY0TK7hdZwqYWb8sn8rHht6Fpmb93DFk1+RveeI17FEqjUVQpApKnbc/59VpNaqwbi+zb2OU+Uu65LGC9f1YNeBPC6b9BXLc/Z5HUmk2lIhBJmZmdms2n6Auwa2pUZMpNdxAqJXi7q8cVNvYqMiGDrlaz5atdPrSCLVkgohiBzIO8bfZq+lW3ptLu7U0Os4AdWqQSJvje9NqwY1GTc9k+e/+tbrSCLVjgohiEyYk8WeIwX84eIOmIX+aablVT8xjlfH9eT8tg3449srefCdVbpes0gAqRCCxKbdh3n2y038omsaZ6Ylex3HM/ExUUwZ2ZVre6fz1BebuPmlxbpes0iAqBCCxJ/eXUVsVCR3XNjG6yiei4ww7r2kA7+/uD3vr9zBra8s4Zim0BapciqEIPDZulw+Wr2LW85vSf3EOK/jBI0xfZpx3yUd+HDVTn7z+nLtPhKpYvpimscKi4p54J1VNK0bz+hz0r2OE3RG9U7nYN4x/vbBOhJiI3lgcMdqeXxFJBBUCB57af4W1u86xJSRXYmNqh6nmZbX+H4tOZhXyJTPNpIYF82dA8Lv29siwcCvXUZmNsDM1ppZlpnddYLnm5jZXDNbYmbLzWyQ7/G6vscPmdmEMut0NbMVvtf8p1XDt337jhTw2Efr6N2iLhe0b+B1nKBlZtw1sC1X9WjC5E82MOmTLK8jiYSlUxaCmUUCE4GBQHtguJm1L7PY74CZzrkuwDBgku/xPOD3wB0neOnJwDigle9nwOkMIJQ9/tF6Dhw9xh9+3l67QU7BzHhgcEcGd27EX99fy/R533odSSTs+PMJoTuQ5Zzb6JwrAF4FBpdZxgFJvtvJwDYA59xh59wXlBTDf5lZQyDJOTfPlcx//AJw6ekPI/Ss23mQ6V9v5qoeTWh7RtKpVxAiI4y//eIsftquPr//90reWpLjdSSRsOJPIaQCpa9mkuN7rLR7gRFmlgPMAm714zVL/9d8otcMW845HnhnFQkxkdz2M51mWh7RkRFMuOpsejWvyx2vLWf2yh1eRxIJG/4Uwon2ZZQ9/2848JxzLg0YBEw3s5O9tj+vWbKg2TgzyzSzzNzcXD/iBr85a3bx+frd/OqnramTEON1nJATFx3JtFEZnJmazK0vL+Hz9eHx70LEa/4UQg7QuNT9NHy7hEoZA8wEcM7NA+KAeqd4zbRTvCa+15vqnMtwzmWkpKT4ETe4FRQW8+C7q2mRksDIXk29jhOyasZG8dzobjRPSWDcC4tYtHmP15FEQp4/hbAQaGVmzcwshpKDxm+XWWYL0B/AzNpRUgg/+rbNObcdOGhmPX1nF10D/Ps08oec57/6lk27D/O7i9sTHanvBVZErfgYXhjTnQZJsVz77EJWbtvvdSSRkHbKv0jOuULgFmA2sJqSs4lWmtn9ZnaJb7HbgevNbBnwCnCt72AxZvYt8ChwrZnllDpD6SbgKSAL2AC8V3nDCk67D+Xzz4/X069NCv3a1Pc6TlionxjHi2N7kBgbxTVPL2BD7iGvI4mELAuli5xnZGS4zMxMr2OctrvfXM5rmTnM/nVfWqTU9DpOWNmQe4ghT84jJiqC127sRVrteK8jiQQFM1vknMvwZ1ntswiQldv28+rCbK7pla4yqAItUmrywpjuHMovZMRT89l1MO/UK4nI96gQAsC5ksti1o6P4X/6t/I6Ttjq0CiZ50Z3Y+eBfK55egH7jhR4HUkkpKgQAuC9b3Ywf9MebvtZa5Ljo72OE9a6Nq3DtGsy2Jh7mGufXcih/EKvI4mEDBVCFcs7VsSfZ62m7RmJDOvW+NQrSIX1aVWPJ67qwoqt+xn3QqYusCPiJxVCFXv6i03k7D3KHy5uT5ROMw2YCzucwSNXduKrDd9xy8uLdYEdET/oL1QV2nkgj4lzs7iwQwN6tzzZ9/SkKlx+dhoPDO7AR6t3ccdry3SBHZFT0PUQqtDD76+hsMjx20FlJ4eVQBnZK50DeYU8MnstNWOjePBSXWBH5MeoEKrI0ux9vLl4Kzed14ImdXVOvJeOX2DnyU83UDMuirsGtFUpiJyACqEKOOe47z8rSUmMZXy/ll7HEeDOAW04lH+MKZ9uJCkuWr8XkRNQIVSBfy/dxpIt+/jrlZ2oGav/i4OBmXH/JR05nF/0391Ho3qnex1LJKjor1Uly9l7hL+8t4YzU5O58uy0U68gARMRYTxyZScO5Rfyx7dXkhAbxZVd9TsSOU6FUAnyC4v4cNVOZizM5ous3URFGBOv7kJEhPZTB5uoyAieGN6FMc8v5DevL6NmbCQDOjb0OpZIUFAhVMDq7QeYsTCbfy3dyr4jx2iUHMet57fiF13TaFxHB5KDVVx0JFNHZjDy6fnc+soSnh4VRd/WoX+tDZGKUiGU04G8Y7y9dBszM7NZnrOfmMgIftahAUMzGnNOy3pE6lNBSEiIjeLZa7szbNrXjJueyYtjepCRXsfrWCKe0vTXfnDOMX/THmYuzGbWN9vJO1ZM2zMSGZLRmMu6pFJbl8EMWbkH8xk6ZR65B/N5ZVxPOqYmex1JpFKVZ/prFcJJ7NifxxuLc5iZmc3m746QGBvFJZ0bMbRbY85MTda57GFi676j/GLyV+QVFjPzhl60rK/pySV8qBAq4FhRMR+v3sXMzGw+WbuLYgc9mtVhaLfGDOzYkBoxkVW6ffHGxtxDDJkyj/iYKD74dV/iovV7lvBQnkLQMQSfrF0HmbEwm7eWbGX3oQLqJ8Zy409aMCSjMen1EryOJ1WseUpNHh/ahRFPz+fFrzcz9tzmXkcSCbhqXQiH8gt5d/k2ZizMZvGWfURFGP3b1Wdot8b0bZWi2UmrmT6t6tG3dQpPzMniF10b69oVUu1Uu0JwzrF4y15mLMzmneXbOVJQRIuUBO4Z1JbLuqSRkhjrdUTx0F0D2nLRE58z6dMs7h7Yzus4IgFVbQoh92A+b/oOEG/IPUx8TCQ/79SIId0ac3aTWjpALAC0b5TEZV1SefbLb7mmVzqptWp4HUkkYMK+EA7nF/LrGUuZs2YXhcWOrk1r89crWnBRp4YkaJ4hOYHbL2jDO8u38+gH6/j7kLO8jiMSMGH/FzE+JpLDBYVc16cZQzLSaFk/0etIEuRSa9VgdO90pn6+kTF9mtG+UZLXkUQCIuyPmpoZL43tyT2D2qkMxG83n9eSpLhoHn5/jddRRAIm7AtB5HQkx0dzS7+WfLouly/W7/Y6jkhAqBBEfsTIXk1JrVWDh95bresxS7WgQhD5EXHRkdxxYWtWbjvAf5Zv8zqOSJVTIYicxOCzUmnfMIlHZq8lv7DI6zgiVUqFIHISERHGPYPakbP3KNPnbfY6jkiVUiGInEKfVvU4t1U9JszNYv/RY17HEakyKgQRP9w1sC37jx5j8icbvI4iUmVUCCJ+6NAomcs6p/LMl5vYtu+o13FEqoQKQcRPt13QGoBHP1zncRKRqqFCEPFTWu14ru2dzhuLc1i9/YDXcUQqnV+FYGYDzGytmWWZ2V0neL6Jmc01syVmttzMBpV67m7femvN7MJSj//azFaa2Tdm9oqZxVXOkESqznjflBZ/eU9TWkj4OWUhmFkkMBEYCLQHhptZ+zKL/Q6Y6ZzrAgwDJvnWbe+73wEYAEwys0gzSwV+CWQ45zoCkb7lRIJa6SktvszSlBYSXvz5hNAdyHLObXTOFQCvAoPLLOOA41NCJgPHv9Y5GHjVOZfvnNsEZPleD0pmWq1hZlFAfKl1RIKaprSQcOVPIaQC2aXu5/geK+1eYISZ5QCzgFtPtq5zbivwN2ALsB3Y75z7oNzpRTxwfEqLb7ZqSgsJL/4UwokuJVb2bdFw4DnnXBowCJhuZhE/tq6Z1abk00MzoBGQYGYjTrhxs3Fmlmlmmbm5uX7EFal6mtJCwpE/hZADNC51P40f7t4ZA8wEcM7NA+KAeidZ96fAJudcrnPuGPAm0PtEG3fOTXXOZTjnMlJSUvyIK1L1IiKMuwe1JWfvUV78eovXcUQqhT+FsBBoZWbNzCyGkoO/b5dZZgvQH8DM2lFSCLm+5YaZWayZNQNaAQt8y/c0s3gruZhxf2B1ZQxIJFDObZXCua3q8cSc9ZrSQsLCKQvBOVcI3ALMpuSP9kzn3Eozu9/MLvEtdjtwvZktA14BrnUlVlLyyWEV8D4w3jlX5JybD7wOLAZW+HJMreSxiVS5OwdoSgsJH+Zc6JwlkZGR4TIzM72OIfI9t81YyrsrtjP3jvNoVKuG13FEvsfMFjnnMvxZVt9UFqmg2y5ojXOa0kJCnwpBpILSasdz7TklU1qs2aEpLSR0qRBEKsHN57UgMTZKU1pISFMhiFSCWvEx3HJ+Sz5Zm8tXmtJCQpQKQaSSXNMr3TelxRpNaSEhSYUgUknioiO5/YLWrNi6n3dWbPc6jki5qRBEKtGlnVNp1zCJR2av0ZQWEnJUCCKVKCLCuHtgW7L3aEoLCT0qBJFK1rd1yZQWEzSlhYQYFYJIFbhzQFv2HjnGk59qSgsJHSoEkSrQMTWZy7qk8swXm9i+/6jXcUT8okIQqSK3H5/S4gNNaSGhQYUgUkXSasczqndTTWkhIUOFIFKFxvdrSc3YKB7WlBYSAlQIIlWoVnwM4/u1ZO7aXL7aoCktJLipEESq2KjeJVNa/EVTWkiQUyGIVLG46Ehu+1lrludoSgsJbioEkQC4tIumtJDgp0IQCYDIUlNavKQpLSRIqRBEAqRv6xT6tKzHE3PWcyBPU1pI8FEhiATQXQN9U1p8oiktJPioEEQCqGNqMpd2bsTTmtJCgpAKQSTAbr+gDc7BYx9qSgsJLioEkQBrXCeea3o15fVFOazdcdDrOCL/pUIQ8cAt57ckMS6a8S8vZs/hAq/jiAAqBBFP1IqPYerIrmTvOcKoZxborCMJCioEEY/0aF6XJ0d0ZfX2A4x9LpOjBfrCmnhLhSDioX5t6/P4sM5kbt7DjS8uoqCw2OtIUo2pEEQ8dnGnRjx0+Zl8ui6XX81YQmGRSkG8EeV1ABGBod2acDCvkAffXU1CzAoevqITERHmdSypZlQIIkFi7LnNOZhXyD8+Xk/NuCj+cHF7zFQKEjgqBJEg8quftuJgXiHPfLmJxLhobvtZa68jSTWiQhAJImbG7y9ux6H8Y/zz4/UkxUUx9tzmXseSakKFIBJkzIyHLu/E4fwiHnx3NTVjoxjWvYnXsaQa8OssIzMbYGZrzSzLzO46wfNNzGyumS0xs+VmNqjUc3f71ltrZheWeryWmb1uZmvMbLWZ9aqcIYmEvsgI47GhnTmvTQp3v7WC/yzb5nUkqQZOWQhmFglMBAYC7YHhZta+zGK/A2Y657oAw4BJvnXb++53AAYAk3yvB/AP4H3nXFvgLGB1xYcjEj5ioiKYfHVXujWtw69nLGXOmp1eR5Iw588nhO5AlnNuo3OuAHgVGFxmGQck+W4nA8ffzgwGXnXO5TvnNgFZQHczSwL6Ak8DOOcKnHP7KjYUkfBTIyaSp6/NoF3DJG56cTFfb/zO60gSxvwphFQgu9T9HN9jpd0LjDCzHGAWcOsp1m0O5ALP+nYzPWVmCeWPLxL+EuOief667jSpE8+Y5xayLFvvnaRq+FMIJzoR2pW5Pxx4zjmXBgwCpptZxEnWjQLOBib7djMdBn5wbALAzMaZWaaZZebm5voRVyT81EmI4cWxPahTM4ZRzy7QtNlSJfwphBygcan7afz/LqHjxgAzAZxz84A4oN5J1s0Bcpxz832Pv05JQfyAc26qcy7DOZeRkpLiR1yR8NQgKY6XxvQkNiqCEU/PZ/N3h72OJGHGn0JYCLQys2ZmFkPJQeK3yyyzBegPYGbtKCmEXN9yw8ws1syaAa2ABc65HUC2mbXxrd8fWFXh0YiEuSZ143lxTA8Ki4q5+qn5ugynVKpTFoJzrhC4BZhNyZlAM51zK83sfjO7xLfY7cD1ZrYMeAW41pVYScknh1XA+8B459zxOX5vBV4ys+VAZ+DPlTkwkXDVqkEiL1zXg/1HjjHiqfl8dyjf60gSJsy5socDgldGRobLzMz0OoZIUFiwaQ/XPDOfFik1efn6niTXiPY6kgQhM1vknMvwZ1lNfy0Soro3q8OTI7qybudBxjy3kCMFhV5HkhCnQhAJYee1qc8/hnVh8Za93DB9EfmFuuqanD4VgkiIG3RmQ/5yRSc+X7+b/3llqS6wI6dNhSASBoZkNOYPF7fn/ZU7uPONFRQXh86xQQkemu1UJExc16cZB/MKeeyjdSTGRfHHn+sCO1I+KgSRMPLL/i05mHeMp77YRGJcFLdf0ObUK4n4qBBEwoiZ8duL2nEov5An5mSRGBfFuL4tvI4lIUKFIBJmzIw/XXYmh/IL+fOsNdSMjeaqHrrAjpyaCkEkDEVGGI8O6czh/EJ++68VJMRGMrhz2UmKRb5PZxmJhKmYqAgmj+hK9/Q63D5zGR+v1gV25ORUCCJhLC46kqdGZdChURI3vbSYh95bTe5BzX0kJ6ZCEAlziXHRPDe6OwM7nsG0zzbS5+E53Pv2Srbt00yp8n2a3E6kGtm0+zCTP8nizcVbMYMrzk7jpvNa0LSuLlgYrsozuZ0KQaQaytl7hKmfbeTVhdkUFhUzuHMqN5/XglYNEr2OJpVMhSAiftl1II+nvtjEi19v5uixIgZ0OIPx/VrSMTXZ62hSSVQIIlIuew4X8OyXm3juq285mFdIvzYp3HJ+S7o2reN1NKkgFYKInJYDeceYPm8zT3+xiT2HC+jVvC63nt+SXi3qal6kEKVCEJEKOVJQyMvztzD1s43sOphPlya1uPX8lvRrU1/FEGJUCCJSKfKOFfH6ohwmf7KBrfuO0r5hErec35IBHc4gIkLFEApUCCJSqY4VFfPvpduYNDeLjbsP07J+TW4+rwWXnNWIqEh9nSmYqRBEpEoUFTve+2Y7E+ZksWbHQZrUiefGn7Tgiq6pxEZFeh1PTkCFICJVyjnHx6t38cTcLJZl7+OMpDhu+ElzhnVrQo0YFUMwUSGISEA45/giazcT5mQxf9Me6ibEMPbc5ozo2YTEuGiv4wkqBBHxwMJv9zBhThafrsslKS6K8f1aMq5vc52V5LHyFIKOBolIpeiWXofnr+vO27ecQ7f0Ojz03hrufXslxcWh86azulMhiEil6pRWi6dGZXD9uc14ft5m7nlrBUUqhZCgK6aJSKUzM+4Z1I4a0ZH8c04W+YXFPHJlJ52iGuRUCCJSJcyM2y5oQ2x0JI/MXkt+YRGPD+1CTJRKIVipEESkSo3v15LYqAgefHc1BYWLmHDV2cRF69TUYKSqFpEqN/bc5jxwaUc+Wr2L61/I5GhBkdeR5ARUCCISECN7NuWvV3Tii6zdjH5uAYfzC72OJGWoEEQkYIZ0a8zjQzuz8Nu9jHx6PgfyjnkdSUpRIYhIQA3unMrEq7qwYut+rp42n72HC7yOJD4qBBEJuAEdGzJlZFfW7jzI8Glfs/tQvteRBD8LwcwGmNlaM8sys7tO8HwTM5trZkvMbLmZDSr13N2+9daa2YVl1ov0rfNOxYciIqHk/LYNeGZUN7797jBDp8xj54E8ryNVe6csBDOLBCYCA4H2wHAza19msd8BM51zXYBhwCTfuu199zsAA4BJvtc77n+A1RUdhIiEpj6t6vH86O7s2J/HkCnz2LrvqNeRqjV/PiF0B7KccxudcwXAq8DgMss4IMl3OxnY5rs9GHjVOZfvnNsEZPleDzNLAy4CnqrYEEQklPVoXpfpY3uw53ABQ56cx+bvDnsdqdrypxBSgexS93N8j5V2LzDCzHKAWcCtfqz7OPAboLh8kUUk3JzdpDavXN+TIwWFDJkyjw25h7yOVC35Uwgnmru27ExVw4HnnHNpwCBguplF/Ni6ZnYxsMs5t+iUGzcbZ2aZZpaZm5vrR1wRCUUdU5N5dVwvioodQ6fMY82OA15Hqnb8KYQcoHGp+2n8/y6h48YAMwGcc/OAOKDeSdY9B7jEzL6lZBfU+Wb24ok27pyb6pzLcM5lpKSk+BFXREJVmzMSeXVcLyIjjGFTv+abrfu9jlSt+FMIC4FWZtbMzGIoOUj8dplltgD9AcysHSWFkOtbbpiZxZpZM6AVsMA5d7dzLs05l+57vTnOuRGVMiIRCWkt69dk5g29SIiJYvi0r1m8Za/XkaqNUxaCc64QuAWYTckZQTOdcyvN7H4zu8S32O3A9Wa2DHgFuNaVWEnJJ4dVwPvAeOecJjERkZNqWjeBmTf2ok5CDCOfms/8jd95Hala0CU0RSRo7TyQx1XTvmbrvqM8dU03+rSq53WkkKNLaIpIWGiQFMeMG3qRXjeB655fyJw1O72OFNZUCCIS1OrVjOWV63vSpkEiN0xfxPvfbPc6UthSIYhI0KudEMNL1/fgzNRkxr+8hH8v3ep1pLCkQhCRkJAUF80LY3qQ0bQ2v5qxlJmZ2adeScpFhSAiIaNmbBTPje5On5b1+M3ry5n+9WavI4UVFYKIhJQaMZFMuyaDn7arz+//9Q1Pfb7R60hhQ4UgIiEnLjqSSVd3ZWDHM3jw3dVMnJvldaSwoEIQkZAUExXBE8O7cGnnRjwyey0Pvbea4uLQ+V5VMIryOoCIyOmKiozg70M6kxAbxZRPN7JtXx6PXNmJuOjIU68sP6BCEJGQFhlhPHhpRxrXiecv761hx/6jTB2ZQe2EGK+jhRztMhKRkGdm3PiTFjwxvAvLcvZz+eSvdKGd06BCEJGw8fOzGvHS2B7sPVLAZZO+0kyp5aRCEJGw0i29Dm/e1JvEuCiGT/2a91Zoqgt/qRBEJOw0T6nJmzf1pkOjJG5+eTFPfb6RUJrZ2SsqBBEJS3VrxvLy9T0Z0KHkuwr3vr2SIp2WelIqBBEJW3HRkUy86mzG9W3O8/M2c8P0TI4UFHodK2ipEEQkrEVEGPcMascDgzswZ80uhk75ml0H87yOFZRUCCJSLYzslc60azLI2nWIyyZ+xbqdB72O5JcjBYUszd4XkG2pEESk2ujfrgEzb+hFQVExV0z+iq827PY60o86kHeMiXOz6PPwXEY/u4C8Y1V/OXoVgohUK2emJfPWzb05IymOUc8s4I1FOV5H+p49hwv4+wdrOecvc3hk9lo6pSUz7ZqMgEzHoakrRKTaSasdz+s39eamFxdx+2vLyNl7lF/2b4mZeZZp14E8pn2+kZfmb+FIQREDOpzBLee3pGNqcsAyqBBEpFpKrhHNc6O7c/ebK3jso3Vk7z3Cny87k5iowO442brvKFM+3cCrC7MpLCrmkrMacXO/lrRukBjQHKBCEJFqLCYqgr/9ohON69Tg8Y/Ws33/USZd3ZXkGtFVvu1Nuw8z+ZMs3ly8FTO44uw0bvxJC9LrJVT5tn+MCkFEqjUz41c/bU1a7XjuemM5v3jyK54d3Z3UWjWqZHtrdxxk4tws3ll+AlycAAAINklEQVS+jejICEb0bMq4vs1pVEXbKw8VgogIcGXXNBolx3HDi4u4dOKXPHttt0rdf788Zx8T5mTxwaqdJMREcn3f5ozt05yUxNhK20ZFWSjN75GRkeEyMzO9jiEiYWzdzoOMfnYhe48UMOGqLpzftkGFXm/ht3t4Yk4Wn63LJSkuitHnNGP0OenUig/M9RrMbJFzLsOvZVUIIiLft+tAHtc9v5BV2w5w3+COjOzZtFzrO+f4Ims3T8zJYsGmPdRNiGHsuc0Z0bMJiXFVf3yitPIUgnYZiYiUUT8pjhnjevHLV5bw+399Q/aeI9w1oC0RESc/LdU5x0erdzFhznqW5eznjKQ4/vjz9gzr1oQaMcF/WU8VgojICSTERjFlZFfu+88qpn62kZy9R3h0SOcTfkGsqNgxa8V2Js7NYs2OgzSuU4OHLj+Ty89OJTYq+IvgOBWCiMiPiIqM4P7BHWhaN54/zVrNzgPzmXZNBnV812s+VlTMv5ZsZfInG9i4+zAt69fksaFn8fNOjYiKDL2JIFQIIiInYWaMPbc5qbVq8KsZS7l80pdMGZnBgm/38OQnG9i67yjtGyYx+eqzubDDGafcrRTMVAgiIn4YeGZD6ifFcf0LmVz4+GcAnN2kFg9c2oF+bep7Ou1FZVEhiIj4qWvT2rx5U2+mfb6Rizo1pFfzumFRBMepEEREyiG9XgJ/uuxMr2NUCb+OepjZADNba2ZZZnbXCZ5vYmZzzWyJmS03s0Glnrvbt95aM7vQ91hj3/KrzWylmf1P5Q1JREROxyk/IZhZJDAR+BmQAyw0s7edc6tKLfY7YKZzbrKZtQdmAem+28OADkAj4CMzaw0UArc75xabWSKwyMw+LPOaIiISQP58QugOZDnnNjrnCoBXgcFllnFAku92MrDNd3sw8KpzLt85twnIAro757Y75xYDOOcOAquB1IoNRUREKsKfQkgFskvdz+GHf7zvBUaYWQ4lnw5u9XddM0sHugDz/cwsIiJVwJ9CONEh9LITIA0HnnPOpQGDgOlmFnGqdc2sJvAG8Cvn3IETbtxsnJllmllmbm6uH3FFROR0+FMIOUDjUvfT+P9dQseNAWYCOOfmAXFAvZOta2bRlJTBS865N39s4865qc65DOdcRkpKih9xRUTkdPhTCAuBVmbWzMxiKDlI/HaZZbYA/QHMrB0lhZDrW26YmcWaWTOgFbDASk7cfRpY7Zx7tHKGIiIiFXHKs4ycc4VmdgswG4gEnnHOrTSz+4FM59zbwO3ANDP7NSW7hK51JfNqrzSzmcAqSs4sGu+cKzKzPsBIYIWZLfVt6h7n3KxKH6GIiPglpK6HYGa5wObTXL0esLsS4wQTjS10hfP4NLbg0NQ559f+9pAqhIows0x/LxIRajS20BXO49PYQk/ozc8qIiJVQoUgIiJA9SqEqV4HqEIaW+gK5/FpbCGm2hxDEBGRk6tOnxBEROQkQr4Q/JiaO9bMZvien++bO6n0803M7JCZ3RGozOVRkfGZWSczm+ebYnyFmcUFMvupnO7YzCzazJ73jWm1md0d6Oyn4sfY+prZYjMrNLMryzw3yszW+35GBS61/053fGbWudS/yeVmNjSwyU+tIr873/NJZrbVzCYEJnElcs6F7A8lX5TbADQHYoBlQPsyy9wMPOm7PQyYUeb5N4DXgDu8Hk9ljo+SLx0uB87y3a8LRHo9pkoa21WUzKILEA98C6R7PaZyji0d6AS8AFxZ6vE6wEbf/9b23a7t9ZgqcXytgVa+242A7UAtr8dUGWMr9fw/gJeBCV6Pp7w/of4JwZ+puQcDz/tuvw70902dgZldSsl/cCsDlLe8KjK+C4DlzrllAM6575xzRQHK7Y+KjM0BCWYWBdQACoATTo7okVOOzTn3rXNuOVBcZt0LgQ+dc3ucc3uBD4EBgQhdDqc9PufcOufcet/tbcAuIJgmKavI7w4z6wo0AD4IRNjKFuqF4M/U3P9dxjlXCOwH6ppZAnAncF8Acp6u0x4fJe/EnJnN9n28/U0A8pZHRcb2OnCYkneXW4C/Oef2VHXgcvBnbFWxbqBUSkYz607Ju/ANlZSrMpz22HwzPP8d+N8qyBUQoX5NZX+m5v6xZe4DHnPOHbLgvUh2RcYXBfQBugFHgI/NbJFz7uPKjXjaKjK27kARJbscagOfm9lHzrmNlRvxtPkztqpYN1AqnNHMGgLTgVHOuR+80/ZQRcZ2MzDLOZcdxH9TTirUC8GfqbmPL5Pj28WQDOwBegBXmtlfgVpAsZnlOeeC6UBQRcaXA3zqnNsNYGazgLOBYCmEioztKuB959wxYJeZfQlkULL7Lxj4M7aTrXtemXU/qZRUlaci48PMkoB3gd85576u5GwVVZGx9QLONbObgZpAjJkdcs794MB0sAr1XUb+TM39NnD8TI0rgTmuxLnOuXTnXDrwOPDnICsDqMD4KJmdtpOZxfv+mP6Ekllng0VFxrYFON9KJAA9gTUByu0Pf8b2Y2YDF5hZbTOrTcmxoNlVlPN0nfb4fMu/BbzgnHutCjOertMem3PuaudcE9/flDsoGWPIlAEQ2mcZlfxtYBCwjpL9kL/1PXY/cInvdhwlZxFlAQuA5id4jXsJwrOMKjo+YAQlB8y/Af7q9Vgqa2yUvPt6zTe2VcD/ej2W0xhbN0rejR4GvgNWllr3Ot+Ys4DRXo+lMsfn+zd5DFha6qez1+OprN9dqde4lhA8y0jfVBYRESD0dxmJiEglUSGIiAigQhARER8VgoiIACoEERHxUSGIiAigQhARER8VgoiIAPB/yBbgB7h81+0AAAAASUVORK5CYII=\n",
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
<<<<<<< HEAD
=======
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt    \n",
    "                    \n",
    "plt.plot(ccc, c_scores)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test this baby out!"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 25,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = [i[1][\"content\"] for i in tweets.iterrows()]\n",
    "rating_list = [i[1][\"rating\"] for i in tweets.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 26,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "twitter_cleaned = preprocess_reviews(tweets_list)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 27,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
<<<<<<< HEAD
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 3), preprocessor=None,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 26,
=======
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None,\n",
       "        stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs',... 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"],\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 27,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "ngram_vectorizer_tweets = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer_tweets.fit(twitter_cleaned)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 28,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(101, 139767)"
      ]
     },
     "execution_count": 27,
=======
       "(101, 139447)"
      ]
     },
     "execution_count": 28,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tws = ngram_vectorizer.transform(twitter_cleaned)\n",
    "tws.shape\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 38,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final.predict(tws[:100])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 39,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
=======
       "      <td>1</td>\n",
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           0       0\n",
       "1           0       0\n",
       "2           0       1\n",
<<<<<<< HEAD
       "3           0       1\n",
       "4           1       1"
      ]
     },
     "execution_count": 29,
=======
       "3           1       1\n",
       "4           1       1"
      ]
     },
     "execution_count": 39,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": rating_list[:100]}).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 50,
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Accuracy: 0.75\n"
=======
      "Accuracy: 0.7326732673267327\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "score = 0\n",
    "for i, j in zip(predictions, rating_list):\n",
    "    total += 1\n",
    "    if i == j:\n",
    "        score += 1\n",
    "        \n",
    "print(f\"Accuracy: {score/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nary tang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model_svc.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final, \"final_model_svc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using trained model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    retrieve_model = joblib.load(\"final_model_svc.pkl\")\n",
    "    print(\"using trained model\")\n",
    "except:\n",
    "    print(\"model not found\")\n",
    "    joblib.dump(final, \"final_model_svc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Postitive and Negative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "('fuck', 0.8981564574760798)\n",
      "('gay', 0.8497220783005143)\n",
      "('emo', 0.7573379173608065)\n",
      "('bitch', 0.7543373668368267)\n",
      "('ass', 0.6446738117454003)\n",
      "('fucking', 0.6263861326090149)\n",
      "('whore', 0.5953503840309493)\n",
      "('loser', 0.5806462563707099)\n",
      "('sucks', 0.5134259491804336)\n",
      "('hate', 0.4927666455539084)\n",
      "('dick', 0.4677574734110367)\n",
      "('nerd', 0.45739023488563046)\n",
      "('damn', 0.4461901137384585)\n",
      "('fat', 0.43979877383969596)\n",
      "('cunt', 0.42548585249336873)\n",
      "('cock', 0.42212504707191406)\n",
      "('pig', 0.39593588110569167)\n",
      "('ugly', 0.3759107526288944)\n",
      "('slut', 0.36425134151369726)\n",
      "('freak', 0.3546271395326123)\n",
      "('pussy', 0.3258169342927787)\n",
      "('fag', 0.27317407263336985)\n",
      "('whale', 0.250200097573113)\n",
      "('really sucks', 0.24695688719873002)\n",
      "('wow', 0.2397637195792644)\n",
      "('piss', 0.2278619219698679)\n",
      "('shit', 0.20844212465837292)\n",
      "('hate much', 0.1922533811948186)\n",
      "('ur', 0.18822177061787926)\n",
      "('cum', 0.18200382513581476)\n",
      "\n",
      "\n",
      "\n",
      "('nope', -0.23872854910861055)\n",
      "('ever', -0.2364848915689265)\n",
      "('love', -0.23488956629353433)\n",
      "('thanks', -0.2282150380649834)\n",
      "('reason', -0.20466699577416567)\n",
      "('favorite', -0.19960592942941383)\n",
      "('yes', -0.19757503026433534)\n",
      "('im', -0.19755225900038642)\n",
      "('problem', -0.18795979925910122)\n",
      "('good', -0.17789047372755196)\n",
      "('funny', -0.17714736110880044)\n",
      "('sorry', -0.16818550807047372)\n",
      "('fucking awesome', -0.15977266913689447)\n",
      "('tho', -0.15347630520271147)\n",
      "('right', -0.15309981207856627)\n",
      "('weather', -0.15082200120314107)\n",
      "('goes', -0.14914908131123442)\n",
      "('best', -0.14555165524853395)\n",
      "('holiday', -0.14510734136796616)\n",
      "('car', -0.14478822331055494)\n",
      "('part', -0.1425646712905552)\n",
      "('idk', -0.1421159097660207)\n",
      "('tweet', -0.13749844187672536)\n",
      "('cool', -0.13669762229352123)\n",
      "('great', -0.13639861811229123)\n",
      "('cold', -0.1355512956248314)\n",
      "('knew', -0.1355131631130169)\n",
      "('actually', -0.1337586944948107)\n",
      "('never', -0.13182502921240044)\n",
      "('ny', -0.13141807608235556)\n"
=======
      "('fuck', 0.8832945558863153)\n",
      "('gay', 0.8122463917114521)\n",
      "('bitch', 0.7562103615559161)\n",
      "('emo', 0.7382007519789737)\n",
      "('ass', 0.6480757091859153)\n",
      "('fucking', 0.6377205726497154)\n",
      "('loser', 0.6064767156785721)\n",
      "('whore', 0.57811374929683)\n",
      "('sucks', 0.5050615613122257)\n",
      "('hate', 0.4846680212793077)\n",
      "('nerd', 0.48216680884759816)\n",
      "('cunt', 0.4799606801478932)\n",
      "('damn', 0.46249661749476645)\n",
      "('cock', 0.45851629935261573)\n",
      "('fat', 0.43402001981305327)\n",
      "('dick', 0.41371307481923575)\n",
      "('slut', 0.3827450527853783)\n",
      "('pig', 0.36331459098011065)\n",
      "('ugly', 0.3390199966544164)\n",
      "('freak', 0.336713106571376)\n",
      "('pussy', 0.3234374309894383)\n",
      "('piss', 0.2771399980657057)\n",
      "('really sucks', 0.27165348215152046)\n",
      "('fag', 0.26645479110648396)\n",
      "('whale', 0.25463027808337624)\n",
      "('wow', 0.23891221397136417)\n",
      "('ur', 0.23192750507638524)\n",
      "('suck', 0.21878501248329155)\n",
      "('hoe', 0.20820565994153176)\n",
      "('cum', 0.1830298385368222)\n",
      "\n",
      "\n",
      "\n",
      "('ever', -0.25723081464809044)\n",
      "('thanks', -0.2511597147008126)\n",
      "('love', -0.22527421825648705)\n",
      "('nope', -0.2216447795557415)\n",
      "('favorite', -0.20020047199900975)\n",
      "('im', -0.19940148206651226)\n",
      "('yes', -0.18110338556103658)\n",
      "('reason', -0.16444370162931873)\n",
      "('sorry', -0.15882708980322072)\n",
      "('part', -0.15627935557276576)\n",
      "('good', -0.15532574439302999)\n",
      "('worth', -0.15306030208877602)\n",
      "('fucking awesome', -0.15081373169142867)\n",
      "('funny', -0.1497793701149914)\n",
      "('think', -0.14906988387868558)\n",
      "('tho', -0.14671141706625462)\n",
      "('video', -0.14594547712246211)\n",
      "('gt', -0.14486057348453335)\n",
      "('sure', -0.14368279359517583)\n",
      "('feeling', -0.14156848918168366)\n",
      "('hungry', -0.14042141744516817)\n",
      "('need', -0.13724729436281585)\n",
      "('long', -0.1357117208066807)\n",
      "('idk', -0.1333868378575251)\n",
      "('world', -0.13247475838722342)\n",
      "('right', -0.1317985302002794)\n",
      "('kinda', -0.13144314918289257)\n",
      "('mine', -0.12893836655272353)\n",
      "('ny', -0.1288711186908097)\n",
      "('personally', -0.1283385301805761)\n"
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        ngram_vectorizer.get_feature_names(), final.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:30]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:30]:\n",
    "    print (best_negative)"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-36-7525c19e9dcc>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-36-7525c19e9dcc>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    lr = LogisticRegression(C=c, gamma)\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c, gamma)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "final = LinearSVC(C=0.01)\n",
    "final.fit(X, y)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_test, final.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = final.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 571203fe974a5fabe21ec4a46b080412521d9a94
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
